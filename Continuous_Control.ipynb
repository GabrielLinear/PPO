{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## DIFFERENCE BETWEEN PONG AND OUR ENVIRONMENT ##############################\n",
    "# num_agent : 20 -> 20 agent\n",
    "# Size of each action : 4 -> One action is size(4) AND continuous.\n",
    "# Difference Not (1) -> But\n",
    "# In PONG : 1 last output probability of action 5 or 4.\n",
    "#     # convert states to policy (or probability)\n",
    "# new_probs = pong_utils.states_to_prob(policy, states)\n",
    "# new_probs = torch.where(actions == pong_utils.RIGHT, new_probs, 1.0-new_probs)\n",
    "# the output is the probability of moving right\n",
    "# P(left) = 1-P(right)\n",
    "# outi​={xi​yi​​if conditioni​otherwise​}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from unityagents import UnityEnvironment\n",
    "import collections\n",
    "from multiprocessing import Process\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size,nb_action):\n",
    "        super(Policy, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size,300)\n",
    "        self.fc2 = nn.Linear(300,300)\n",
    "        self.fc3 = nn.Linear(300,nb_action)\n",
    "        self.fc3bis = nn.Linear(300,nb_action)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mu = F.tanh(self.fc3(x))\n",
    "        sigma = F.tanh(self.fc3bis(x)) # ¨b donne des sigma avec 0 veut que des sigma positif\n",
    "        sigma = torch.exp(sigma)\n",
    "        m = torch.distributions.normal.Normal(mu,sigma,False) # False, whereas constraint on mu = 0\n",
    "        sample = m.sample()#.detach()\n",
    "        proba = m.log_prob(sample)\n",
    "        probab = torch.exp(proba)\n",
    "        # action\n",
    "        action_sample = torch.clip(sample.detach(), -1, 1)\n",
    "        \n",
    "        \n",
    "        # Every entry in the action vector must be a number between -1 and 1\n",
    "        return probab,action_sample,mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size,nb_action):\n",
    "        super(Policy, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size,300)\n",
    "        self.fc2 = nn.Linear(300,300)\n",
    "        self.fc3 = nn.Linear(300,nb_action)\n",
    "        self.fc3bis = nn.Linear(300,nb_action)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mu = F.tanh(self.fc3(x))\n",
    "        sigma = F.tanh(self.fc3bis(x)) # ¨b donne des sigma avec 0 veut que des sigma positif\n",
    "        sigma = torch.exp(sigma)\n",
    "        m = torch.distributions.normal.Normal(mu,sigma,False) # False, whereas constraint on mu = 0\n",
    "        # Every entry in the action vector must be a number between -1 and 1\n",
    "        return mu,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_prob(policy,states):\n",
    "    Tab = []\n",
    "    Action_sample_tab = []\n",
    "    mu_tab = []\n",
    "    #proba,action_sample,mu = policy.forward(states[0])\n",
    "    mu,m = policy.forward(states[0])\n",
    "    sample = m.sample()#.detach()\n",
    "    proba = m.log_prob(sample)\n",
    "    probab = torch.exp(proba)\n",
    "    #action_sample = torch.clip(sample.detach(), -1, 1)\n",
    "    \n",
    "    # STORE\n",
    "    Tab.append(probab)\n",
    "    Action_sample_tab.append(sample)\n",
    "    mu_tab.append(mu)\n",
    "    #new_probs = torch.tensor(proba.unsqueeze(0))\n",
    "    for state_iter in states[1:]:\n",
    "        #proba,action_sample,mu = policy.forward(state_iter)\n",
    "        mu,m = policy.forward(states[0])\n",
    "        sample = m.sample()#.detach()\n",
    "        proba = m.log_prob(sample)\n",
    "        probab = torch.exp(proba)\n",
    "        Tab.append(probab)\n",
    "        Action_sample_tab.append(sample)\n",
    "        mu_tab.append(mu)\n",
    "        #pr()\n",
    "        #proba = proba.detach().cpu().numpy() # Not Detach because needed !\n",
    "        #new_probs = torch.cat((new_probs,proba.unsqueeze(0)))\n",
    "    return torch.stack(Tab),torch.stack(Action_sample_tab),torch.stack(mu_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_surrogate(policy, old_probs, states, rewards,\n",
    "                      discount = 0.995, epsilon=0.1, beta=0.01):\n",
    "    \n",
    "    #actions = torch.tensor(actions, dtype=torch.int8, device=device)\n",
    "\n",
    "    # convert states to policy (or probability)\n",
    "    new_probs,action_sample,mu = New_prob(policy, states)\n",
    "    \n",
    "    #new_probs = np.asarray(new_probs)\n",
    "    #new_probs = torch.from_numpy(new_probs).to(device)\n",
    "    #print(new_probs)\n",
    "    #print(new_probs.shape) # [Nb_iteration,Nb_agent,Values entre -1 et 1]\n",
    "    \n",
    "    old_probs = np.asarray(old_probs)\n",
    "    old_probs = torch.from_numpy(old_probs).to(device)\n",
    "    #print(old_probs)\n",
    "    Fraction = torch.div(new_probs,old_probs+1e-10) # Changed\n",
    "    #print(Fraction.shape)\n",
    "    \n",
    "    # Convert REWARD TO REWARD FUTURE\n",
    "    rewards = np.asarray(rewards)\n",
    "    reward_futur = np.zeros((rewards.shape[0],rewards.shape[1]))\n",
    "    longueur = rewards.shape[0] - 1\n",
    "    reward_futur[longueur] = rewards[longueur]\n",
    "    new_discount = 0\n",
    "    for i in range(1,rewards.shape[0]):\n",
    "        new_discount = discount**(longueur-i) \n",
    "        reward_futur[longueur-i] = reward_futur[longueur-(i-1)] + rewards[longueur-i]*new_discount\n",
    "        \n",
    "    # Compute normal reward\n",
    "    mean = np.mean(reward_futur, axis=1)\n",
    "    std = np.std(reward_futur, axis=1)+1.0e-10\n",
    "    normalized_rewards = (reward_futur-mean[:, np.newaxis])/std[:, np.newaxis]\n",
    "    normalized_rewards = torch.from_numpy(normalized_rewards).float().to(device)\n",
    "    normalized_rewards = normalized_rewards.unsqueeze(2)\n",
    "    normalized_rewards = normalized_rewards.repeat(1, 1, Fraction.shape[2])\n",
    "\n",
    "    # Compute each \n",
    "    #print(normalized_rewards.shape)\n",
    "    Cote1 = normalized_rewards*Fraction\n",
    "    #print(Cote1)\n",
    "    Cote2 = normalized_rewards*torch.clamp(Fraction, 1-epsilon, 1+epsilon)\n",
    "    #print(Cote1)\n",
    "    Cote1 = Cote1[:, :,:, None]\n",
    "    Cote2 = Cote2[:, :,:, None]\n",
    "    #print(Cote2.shape)\n",
    "    comp = torch.cat((Cote1, Cote2),3)\n",
    "    #print(comp.shape)\n",
    "    Gradient = torch.min(comp,3)[0].to(device)\n",
    "    #print(Gradient.shape)\n",
    "\n",
    "    # include a regularization term\n",
    "    # this steers new_policy towards 0.5\n",
    "    # prevents policy to become exactly 0 or 1 helps exploration\n",
    "    # add in 1.e-10 to avoid log(0) which gives nan\n",
    "    entropy = -(new_probs*torch.log(old_probs+1.e-10)+ \\\n",
    "        (1.0-new_probs)*torch.log(1.0-old_probs+1.e-10))\n",
    "    #print(entropy.shape)\n",
    "    #print(entropy)\n",
    "    #L= torch.mean(beta*(entropy) +Gradient)\n",
    "    \n",
    "    return torch.mean(beta*(entropy) +Gradient) #*(action_sample-mu)) # Add Action_sample - mu for the Normal derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = clipped_surrogate(policy, prob, states, rewards, epsilon=epsilon, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"C:/Users/gabyc/Desktop/Reinforcment_TP/deep-reinforcement-learning/p2_continuous-control/Multi_agent/Reacher_Windows_x86_64/Reacher.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectories(env,env_info,policy,device):\n",
    "    # DEAL WITH THAT OLD_PROB AND ACTION ARE DIFFERENT NOW.\n",
    "    brain_name = env.brain_names[0]\n",
    "    brain = env.brains[brain_name]\n",
    "    state = env_info.vector_observations # get the current state (for each agent)\n",
    "    states_tab , action_tab, reward_tab, prob_tab = [],[],[], []\n",
    "    while True:\n",
    "        state = torch.from_numpy(state).to(device)\n",
    "        policy.eval()\n",
    "        with torch.no_grad():\n",
    "            #proba,action_sample,mu = policy(state) # Batch of 21\n",
    "            mu,m = policy(state) \n",
    "\n",
    "        # Treatment\n",
    "        #proba = proba.detach().cpu().numpy()\n",
    "        #action = mu.detach().cpu().numpy()\n",
    "        action = torch.clip(mu.detach().cpu(), -1, 1)\n",
    "        action = action.numpy()\n",
    "        sample = m.sample()       \n",
    "        proba = m.log_prob(sample)\n",
    "        proba = torch.exp(proba).detach().cpu().numpy()\n",
    "        \n",
    "        # Step the environment\n",
    "        env_info = env.step(action)[brain_name]           # send all actions to the environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        \n",
    "        # Store values\n",
    "        action_tab.append(action)\n",
    "        prob_tab.append(proba)\n",
    "        reward_tab.append(np.asarray(rewards))\n",
    "        states_tab.append(state)\n",
    "        \n",
    "        # BREAK IF END OF THE EPISODE\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "        state = next_states\n",
    "    return states_tab, action_tab, reward_tab,prob_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]  \n",
    "states = env_info.vector_observations # get the current state (for each agent\n",
    "num_agents = len(states)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "nb_states = len(states[0])\n",
    "action_size = brain.vector_action_space_size\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy = Policy(nb_states,action_size).to(device)\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007842157666871955\n",
      "0.000879620359959332\n",
      "0.0004335664238754686\n",
      "0.00019180818752094464\n",
      "0.00011088910841054611\n",
      "6.193806055363837e-05\n",
      "8.19180800870701e-05\n",
      "6.443556299531733e-05\n",
      "2.297702246344649e-05\n",
      "0.00011888111622391881\n",
      "4.44555434618856e-05\n",
      "2.7972027346804426e-05\n",
      "5.044954932191512e-05\n",
      "2.297702246344649e-05\n",
      "1.1488511231723246e-05\n",
      "6.193806055363837e-05\n",
      "2.4475523928453873e-05\n",
      "5.894105762362361e-05\n",
      "8.741258545876383e-05\n",
      "0.00011438561182889667\n",
      "################################\n",
      "Episode: 20, score: 0.000114\n",
      "0.00011438561182889667\n",
      "6.693306543699631e-05\n",
      "6.143856006530258e-05\n",
      "0.00013086912794397785\n",
      "0.0002002996958226531\n",
      "0.00048151847075570477\n",
      "0.0006073925938163247\n",
      "0.0005369630249609778\n",
      "0.0004320679224104612\n",
      "0.0007682317510604501\n",
      "0.0005389610269143209\n",
      "0.0006353646211631291\n",
      "0.0006188811050480479\n",
      "0.0003726273642985018\n",
      "0.0003956043867619483\n",
      "0.0005564435440060738\n",
      "0.0008121877940339999\n",
      "0.0009725274507897896\n",
      "0.00095704293565138\n",
      "0.0009730269512781254\n",
      "0.0008946053746094058\n",
      "################################\n",
      "Episode: 40, score: 0.000895\n",
      "0.0008946053746094058\n",
      "0.0007872127696172103\n",
      "0.0007217782056452213\n",
      "0.0007487512320153542\n",
      "0.0007217782056452213\n",
      "0.0007742257569204797\n",
      "0.000662337647533262\n",
      "0.0007797202622921734\n",
      "0.0006613386465565903\n",
      "0.0007382617217603025\n",
      "0.0008316683130790959\n",
      "0.000870129850680952\n",
      "0.0008106892925689925\n",
      "0.0007017981861117896\n",
      "0.0006918081763450738\n",
      "0.000773226755943808\n",
      "0.0007317682154119372\n",
      "0.0009385614175829556\n",
      "0.0008236763052657231\n",
      "0.001053946030388524\n",
      "0.0008951048750977416\n",
      "################################\n",
      "Episode: 60, score: 0.000895\n",
      "0.0008951048750977416\n",
      "0.0007847152671755313\n",
      "0.0007142856983201844\n",
      "0.0008351648164974464\n",
      "0.0006978021822051033\n",
      "0.0009655344439530885\n",
      "0.001176823150519129\n",
      "0.0009340659131879335\n",
      "0.0008116882935456641\n",
      "0.0008201798018473727\n",
      "0.0007967032788955904\n",
      "0.0009150848946311733\n",
      "0.0008871128672843689\n",
      "0.0007397602232253099\n",
      "0.0008911088711910552\n",
      "0.0005614385488894317\n",
      "0.0005189810073808893\n",
      "0.0005489510366810369\n",
      "0.0006853146699967084\n",
      "0.0007312687149236014\n",
      "0.0006883116729267232\n",
      "################################\n",
      "Episode: 80, score: 0.000688\n",
      "0.0006883116729267232\n",
      "0.0005694305567028044\n",
      "0.0008371628184507896\n",
      "0.0005864135733062213\n",
      "0.0007777222603388301\n",
      "0.0005394605274026568\n",
      "0.000628371614326428\n",
      "0.000536463524472642\n",
      "0.0007342657178536162\n",
      "0.0006628371480215977\n",
      "0.0006088910952813321\n",
      "0.00037412586576350917\n",
      "0.0002227772177977638\n",
      "0.00025724275149293356\n",
      "0.0003206793135115793\n",
      "0.0004130869038537011\n",
      "0.0003956043867619483\n",
      "0.00022827172316945756\n",
      "0.0003671328589268081\n",
      "0.0006043955908863099\n",
      "0.0007457542290853394\n",
      "################################\n",
      "Episode: 100, score: 0.000746\n",
      "0.0007457542290853394\n",
      "0.0008161837979406862\n",
      "0.0006923076768334095\n",
      "0.0007802197627805092\n",
      "0.0008981018780277564\n",
      "0.0008436563247991549\n",
      "0.0007797202622921734\n",
      "0.0007742257569204797\n"
     ]
    }
   ],
   "source": [
    "###################################################### MAIN_CODE #################################################\n",
    "# training loop max iterations\n",
    "episode = 500\n",
    "\n",
    "# widget bar to display progress\n",
    "#!pip install progressbar\n",
    "#import progressbar as pb\n",
    "#widget = ['training loop: ', pb.Percentage(), ' ', pb.Bar(), ' ', pb.ETA() ]\n",
    "#timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "\n",
    "discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta = .01\n",
    "tmax = 320\n",
    "SGD_epoch = 6\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    states, actions, rewards,prob = collect_trajectories(env,env_info, policy,device)\n",
    "    total_rewards = np.mean(rewards)\n",
    "    print(total_rewards)\n",
    "\n",
    "    # gradient ascent step\n",
    "    for _ in range(SGD_epoch):\n",
    "        \n",
    "        # uncomment to utilize your own clipped function!\n",
    "        L = -clipped_surrogate(policy,prob, states, rewards, epsilon=epsilon, beta=beta)\n",
    "        #L.requires_grad_() # I needed to do that to compute something but maybe that means that there is a bug.\n",
    "        optimizer.zero_grad()\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        del L\n",
    "    \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%20 ==0 :\n",
    "        print(\"################################\")\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "        \n",
    "    # update progress widget bar\n",
    "    #timer.update(e+1)\n",
    "    \n",
    "#timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('GTK3Agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'serialized_options'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-6d8f5c5a9398>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSessionLog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEvent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\tensorboard\\compat\\proto\\event_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_summary__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\tensorboard\\compat\\proto\\summary_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_tensor__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\tensorboard\\compat\\proto\\tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_resource__handle__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_types__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\tensorboard\\compat\\proto\\resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_types__pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\tensorboard\\compat\\proto\\tensor_shape_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m   \u001b[0msyntax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'proto3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m   \u001b[0mserialized_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\030org.tensorflow.frameworkB\\021TensorShapeProtosP\\001ZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\\370\\001\\001'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m   \u001b[0mserialized_pb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n+tensorboard/compat/proto/tensor_shape.proto\\x12\\x0btensorboard\\\"{\\n\\x10TensorShapeProto\\x12.\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32!.tensorboard.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tB\\x87\\x01\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01ZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\\xf8\\x01\\x01\\x62\\x06proto3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'serialized_options'"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "#matplotlib.use(\"Agg\")\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_jit_pass_onnx_graph_shape_type_inference(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: int) -> None\n\nInvoked with: graph(%0 : Double(20, 33, strides=[33, 1], requires_grad=0, device=cuda:0),\n      %1 : Float(300, 33, strides=[33, 1], requires_grad=1, device=cuda:0),\n      %2 : Float(300, strides=[1], requires_grad=1, device=cuda:0),\n      %3 : Float(300, 300, strides=[300, 1], requires_grad=1, device=cuda:0),\n      %4 : Float(300, strides=[1], requires_grad=1, device=cuda:0),\n      %5 : Float(4, 300, strides=[300, 1], requires_grad=1, device=cuda:0),\n      %6 : Float(4, strides=[1], requires_grad=1, device=cuda:0),\n      %7 : Float(4, 300, strides=[300, 1], requires_grad=1, device=cuda:0),\n      %8 : Float(4, strides=[1], requires_grad=1, device=cuda:0)):\n  %9 : Float(20, 33, strides=[33, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1](%0) # <ipython-input-182-0488979f2f3b>:13:0\n  %10 : Float(20, 300, strides=[300, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%9, %1, %2) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1848:0\n  %11 : Float(20, 300, strides=[300, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%10) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1299:0\n  %12 : Float(20, 300, strides=[300, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%11, %3, %4) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1848:0\n  %13 : Float(20, 300, strides=[300, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%12) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1299:0\n  %14 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%13, %5, %6) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1848:0\n  %15 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Tanh(%14) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1796:0\n  %16 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%13, %7, %8) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1848:0\n  %17 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Tanh(%16) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1796:0\n  %18 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Exp(%17) # <ipython-input-182-0488979f2f3b>:18:0\n  %19 : Long(2, strides=[1], device=cpu) = onnx::Shape(%15)\n  %20 : Float(20, 4, device=cpu) = onnx::ConstantOfShape[value={0}](%19)\n  %21 : Float(20, 4, strides=[4, 1], device=cpu) = onnx::Add(%20, %15)\n  %22 : Float(20, 4, strides=[4, 1], device=cpu) = onnx::Add(%21, %18)\n  %23 : Long(2, strides=[1], device=cpu) = onnx::Shape(%22)\n  %24 : Float(20, 4, device=cpu) = onnx::Expand(%15, %23)\n  %25 : Long(2, strides=[1], device=cpu) = onnx::Shape(%22)\n  %26 : Float(20, 4, device=cpu) = onnx::Expand(%18, %25)\n  %27 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={20}]() # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:49:0\n  %28 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:49:0\n  %29 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%27)\n  %30 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%28)\n  %31 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%29, %30)\n  %32 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n  %33 : Long(2, strides=[1], device=cpu) = onnx::Reshape(%31, %32)\n  %34 : Long(1, strides=[1], device=cpu) = onnx::Shape(%33)\n  %35 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%34)\n  %36 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %37 : Long(2, strides=[1], device=cpu) = onnx::Mul(%35, %36)\n  %38 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%33, %37)\n  %39 : Long(2, strides=[1], device=cpu) = onnx::Where(%38, %35, %33)\n  %40 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Expand(%24, %39) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:64:0\n  %41 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%27)\n  %42 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%28)\n  %43 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%41, %42)\n  %44 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n  %45 : Long(2, strides=[1], device=cpu) = onnx::Reshape(%43, %44)\n  %46 : Long(1, strides=[1], device=cpu) = onnx::Shape(%45)\n  %47 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%46)\n  %48 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %49 : Long(2, strides=[1], device=cpu) = onnx::Mul(%47, %48)\n  %50 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%45, %49)\n  %51 : Long(2, strides=[1], device=cpu) = onnx::Where(%50, %47, %45)\n  %52 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Expand(%26, %51) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:64:0\n  %53 : Float(*, *, device=cpu) = onnx::RandomNormalLike(%40)\n  %54 : Float(*, *, device=cpu) = onnx::Mul(%52, %53)\n  %55 : Float(*, *, strides=[4, 1], requires_grad=0, device=cuda:0) = onnx::Add(%54, %40) # <ipython-input-182-0488979f2f3b>:24:0\n  %56 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %57 : Float(device=cpu) = onnx::Cast[to=1](%56)\n  %58 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Pow(%26, %57) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\_tensor.py:30:0\n  %59 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Log(%26) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:76:0\n  %60 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Sub(%55, %24) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:77:0\n  %61 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %62 : Float(device=cpu) = onnx::Cast[to=1](%61)\n  %63 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Pow(%60, %62) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\_tensor.py:30:0\n  %64 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Neg(%63) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:77:0\n  %65 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %66 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%58, %65)\n  %67 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Div(%64, %66) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:77:0\n  %68 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Sub(%67, %59) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:77:0\n  %69 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.918939}]()\n  %70 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Sub(%68, %69)\n  %71 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Exp(%70) # <ipython-input-182-0488979f2f3b>:22:0\n  %72 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %73 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %74 : Float(device=cpu) = onnx::Cast[to=1](%72)\n  %75 : Float(device=cpu) = onnx::Cast[to=1](%73)\n  %76 : Float(*, *, strides=[4, 1], requires_grad=0, device=cuda:0) = onnx::Clip(%55, %74, %75) # <ipython-input-182-0488979f2f3b>:24:0\n  return (%71, %76)\n, None, 11",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-226-ea34c73c3de6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\hiddenlayer\\graph.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[1;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytorch_builder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFRAMEWORK_TRANSFORMS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Argument args must be provided for Pytorch models.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mimport_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tensorflow\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtf_builder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFRAMEWORK_TRANSFORMS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\hiddenlayer\\pytorch_builder.py\u001b[0m in \u001b[0;36mimport_graph\u001b[1;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_trace_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mtorch_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimize_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorExportTypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mONNX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;31m# Dump list of nodes (DEBUG only)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\onnx\\__init__.py\u001b[0m in \u001b[0;36m_optimize_trace\u001b[1;34m(graph, operator_export_type)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_optimize_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimize_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_optimize_graph\u001b[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_pass_lint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_onnx_shape_inference\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_pass_onnx_graph_shape_type_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_export_onnx_opset_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _jit_pass_onnx_graph_shape_type_inference(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: int) -> None\n\nInvoked with: graph(%0 : Double(20, 33, strides=[33, 1], requires_grad=0, device=cuda:0),\n      %1 : Float(300, 33, strides=[33, 1], requires_grad=1, device=cuda:0),\n      %2 : Float(300, strides=[1], requires_grad=1, device=cuda:0),\n      %3 : Float(300, 300, strides=[300, 1], requires_grad=1, device=cuda:0),\n      %4 : Float(300, strides=[1], requires_grad=1, device=cuda:0),\n      %5 : Float(4, 300, strides=[300, 1], requires_grad=1, device=cuda:0),\n      %6 : Float(4, strides=[1], requires_grad=1, device=cuda:0),\n      %7 : Float(4, 300, strides=[300, 1], requires_grad=1, device=cuda:0),\n      %8 : Float(4, strides=[1], requires_grad=1, device=cuda:0)):\n  %9 : Float(20, 33, strides=[33, 1], requires_grad=0, device=cuda:0) = onnx::Cast[to=1](%0) # <ipython-input-182-0488979f2f3b>:13:0\n  %10 : Float(20, 300, strides=[300, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%9, %1, %2) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1848:0\n  %11 : Float(20, 300, strides=[300, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%10) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1299:0\n  %12 : Float(20, 300, strides=[300, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%11, %3, %4) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1848:0\n  %13 : Float(20, 300, strides=[300, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%12) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1299:0\n  %14 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%13, %5, %6) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1848:0\n  %15 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Tanh(%14) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1796:0\n  %16 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%13, %7, %8) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1848:0\n  %17 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Tanh(%16) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\nn\\functional.py:1796:0\n  %18 : Float(20, 4, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Exp(%17) # <ipython-input-182-0488979f2f3b>:18:0\n  %19 : Long(2, strides=[1], device=cpu) = onnx::Shape(%15)\n  %20 : Float(20, 4, device=cpu) = onnx::ConstantOfShape[value={0}](%19)\n  %21 : Float(20, 4, strides=[4, 1], device=cpu) = onnx::Add(%20, %15)\n  %22 : Float(20, 4, strides=[4, 1], device=cpu) = onnx::Add(%21, %18)\n  %23 : Long(2, strides=[1], device=cpu) = onnx::Shape(%22)\n  %24 : Float(20, 4, device=cpu) = onnx::Expand(%15, %23)\n  %25 : Long(2, strides=[1], device=cpu) = onnx::Shape(%22)\n  %26 : Float(20, 4, device=cpu) = onnx::Expand(%18, %25)\n  %27 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={20}]() # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:49:0\n  %28 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={4}]() # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:49:0\n  %29 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%27)\n  %30 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%28)\n  %31 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%29, %30)\n  %32 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n  %33 : Long(2, strides=[1], device=cpu) = onnx::Reshape(%31, %32)\n  %34 : Long(1, strides=[1], device=cpu) = onnx::Shape(%33)\n  %35 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%34)\n  %36 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %37 : Long(2, strides=[1], device=cpu) = onnx::Mul(%35, %36)\n  %38 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%33, %37)\n  %39 : Long(2, strides=[1], device=cpu) = onnx::Where(%38, %35, %33)\n  %40 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Expand(%24, %39) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:64:0\n  %41 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%27)\n  %42 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%28)\n  %43 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%41, %42)\n  %44 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n  %45 : Long(2, strides=[1], device=cpu) = onnx::Reshape(%43, %44)\n  %46 : Long(1, strides=[1], device=cpu) = onnx::Shape(%45)\n  %47 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%46)\n  %48 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %49 : Long(2, strides=[1], device=cpu) = onnx::Mul(%47, %48)\n  %50 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%45, %49)\n  %51 : Long(2, strides=[1], device=cpu) = onnx::Where(%50, %47, %45)\n  %52 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Expand(%26, %51) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:64:0\n  %53 : Float(*, *, device=cpu) = onnx::RandomNormalLike(%40)\n  %54 : Float(*, *, device=cpu) = onnx::Mul(%52, %53)\n  %55 : Float(*, *, strides=[4, 1], requires_grad=0, device=cuda:0) = onnx::Add(%54, %40) # <ipython-input-182-0488979f2f3b>:24:0\n  %56 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %57 : Float(device=cpu) = onnx::Cast[to=1](%56)\n  %58 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Pow(%26, %57) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\_tensor.py:30:0\n  %59 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Log(%26) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:76:0\n  %60 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Sub(%55, %24) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:77:0\n  %61 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %62 : Float(device=cpu) = onnx::Cast[to=1](%61)\n  %63 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Pow(%60, %62) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\_tensor.py:30:0\n  %64 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Neg(%63) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:77:0\n  %65 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n  %66 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%58, %65)\n  %67 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Div(%64, %66) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:77:0\n  %68 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Sub(%67, %59) # C:\\Users\\gabyc\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\torch\\distributions\\normal.py:77:0\n  %69 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.918939}]()\n  %70 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Sub(%68, %69)\n  %71 : Float(*, *, strides=[4, 1], requires_grad=1, device=cuda:0) = onnx::Exp(%70) # <ipython-input-182-0488979f2f3b>:22:0\n  %72 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n  %73 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n  %74 : Float(device=cpu) = onnx::Cast[to=1](%72)\n  %75 : Float(device=cpu) = onnx::Cast[to=1](%73)\n  %76 : Float(*, *, strides=[4, 1], requires_grad=0, device=cuda:0) = onnx::Clip(%55, %74, %75) # <ipython-input-182-0488979f2f3b>:24:0\n  return (%71, %76)\n, None, 11"
     ]
    }
   ],
   "source": [
    "hl.build_graph(policy,states[0].detach().to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USELESS AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8390, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005159840044508744"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =torch.tensor(1.00000e-03 *-6.9314, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-000215d07730>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy(nb_states,action_size).to(device)\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0101, -0.0718,  0.0199,  ..., -0.0826, -0.1599, -0.0077],\n",
      "        [ 0.1577,  0.0900, -0.0746,  ..., -0.0418, -0.1527,  0.0953],\n",
      "        [ 0.0462,  0.0263,  0.1640,  ...,  0.1208,  0.0626, -0.0682],\n",
      "        ...,\n",
      "        [-0.0324,  0.1004, -0.1033,  ..., -0.0490, -0.1629,  0.1655],\n",
      "        [ 0.0649, -0.0408,  0.0351,  ...,  0.1219, -0.1655, -0.0715],\n",
      "        [-0.1006,  0.1355, -0.1460,  ..., -0.0651, -0.1526,  0.0762]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1167,  0.0005, -0.0731,  0.1386,  0.0610,  0.0647, -0.1133, -0.0944,\n",
      "        -0.0147,  0.1589, -0.0924, -0.0397,  0.1038,  0.0868, -0.1729, -0.0881,\n",
      "         0.0176,  0.0112,  0.0870,  0.0435, -0.1395,  0.0897, -0.0384, -0.0323,\n",
      "        -0.0146,  0.0589, -0.0394,  0.0956, -0.0070, -0.1229,  0.1619,  0.0851,\n",
      "         0.0453, -0.1727, -0.1672, -0.0569,  0.1267, -0.1147, -0.1485, -0.1724,\n",
      "        -0.1143,  0.0903, -0.0558, -0.0407, -0.0624, -0.1169,  0.1055,  0.0206,\n",
      "        -0.0828, -0.0014, -0.1097, -0.0829, -0.0587, -0.0964,  0.0505, -0.1515,\n",
      "        -0.0018,  0.0483,  0.1173, -0.0055,  0.0375,  0.1737,  0.1576,  0.0209,\n",
      "         0.1270,  0.1263, -0.0382,  0.0759,  0.1386,  0.0708,  0.0267, -0.1358,\n",
      "         0.1310, -0.0202, -0.0543, -0.0721, -0.0042,  0.0714, -0.0721, -0.1582,\n",
      "        -0.1343,  0.0614, -0.1706, -0.0118, -0.1239, -0.0737,  0.0165, -0.1478,\n",
      "        -0.0670, -0.0852,  0.1580,  0.0031,  0.0471,  0.0932, -0.0216,  0.1207,\n",
      "         0.1199,  0.0792, -0.0079,  0.0404,  0.1565, -0.0837,  0.1732, -0.0758,\n",
      "        -0.1686, -0.1142,  0.0613,  0.0843, -0.1141,  0.0155,  0.0325, -0.0679,\n",
      "         0.1097,  0.1085, -0.1434,  0.0440, -0.0870,  0.0104, -0.0313, -0.1117,\n",
      "         0.1073, -0.0738, -0.0532,  0.1607,  0.1124,  0.0157,  0.0103, -0.0383,\n",
      "        -0.0411, -0.0794,  0.1344,  0.0739,  0.1383,  0.1370,  0.0417,  0.0267,\n",
      "         0.1647, -0.1083,  0.1470, -0.0018, -0.1629,  0.1011, -0.0321,  0.0435,\n",
      "         0.0416,  0.1220,  0.0661, -0.1289,  0.1089, -0.0269, -0.1109,  0.1090,\n",
      "         0.1372,  0.1421,  0.0493, -0.1648,  0.0524, -0.0893,  0.0221, -0.1253,\n",
      "        -0.1269,  0.0894,  0.1320, -0.0018, -0.1031,  0.1217, -0.1394, -0.1178,\n",
      "         0.0518,  0.0369, -0.1481, -0.0959,  0.0924,  0.1065,  0.0602, -0.0656,\n",
      "        -0.0665, -0.0477, -0.0861,  0.0016,  0.0291, -0.0236,  0.1347,  0.1669,\n",
      "         0.0808, -0.0487,  0.0185, -0.0916,  0.0930, -0.0276,  0.0259,  0.0986,\n",
      "         0.0218,  0.1693, -0.0228, -0.1513, -0.0616, -0.0934, -0.0157, -0.1149,\n",
      "        -0.1690, -0.0201,  0.1456,  0.1010,  0.0540, -0.0446, -0.0473,  0.0862,\n",
      "         0.1250, -0.0783,  0.1665,  0.0883,  0.0879,  0.1141,  0.0368, -0.1510,\n",
      "         0.1608,  0.0489, -0.1100,  0.0561,  0.1683,  0.0207,  0.0613, -0.0620,\n",
      "         0.0534, -0.0460, -0.1465, -0.1583,  0.0888, -0.0714,  0.1659,  0.0236,\n",
      "        -0.1416,  0.0122,  0.0192,  0.0806, -0.1238, -0.0654,  0.1081, -0.0194,\n",
      "        -0.0842,  0.0678,  0.0405, -0.0849,  0.1391, -0.1073,  0.1242, -0.0837,\n",
      "        -0.1461,  0.0046, -0.1065, -0.0391, -0.0510, -0.1457, -0.0835, -0.1485,\n",
      "         0.1122,  0.0542, -0.1178,  0.1068,  0.0249,  0.0631, -0.1252,  0.1021,\n",
      "         0.1349,  0.0620, -0.0217, -0.0944,  0.1277, -0.0278, -0.0911, -0.1577,\n",
      "        -0.0817, -0.1628,  0.1400, -0.0576, -0.1016, -0.1340, -0.1397,  0.1352,\n",
      "         0.1387,  0.1342,  0.1030,  0.1059, -0.1026, -0.0753, -0.1460,  0.0676,\n",
      "        -0.0498, -0.1162, -0.1537,  0.0159, -0.1282, -0.1206,  0.0400,  0.0212,\n",
      "        -0.1411, -0.0592, -0.0213,  0.1157], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0239, -0.0045, -0.0367,  ..., -0.0192, -0.0042, -0.0096],\n",
      "        [ 0.0344, -0.0103,  0.0510,  ...,  0.0405, -0.0435,  0.0086],\n",
      "        [-0.0483, -0.0100,  0.0142,  ..., -0.0014, -0.0370,  0.0129],\n",
      "        ...,\n",
      "        [ 0.0314,  0.0038, -0.0541,  ...,  0.0176, -0.0032, -0.0224],\n",
      "        [-0.0118, -0.0457, -0.0577,  ...,  0.0405, -0.0006, -0.0468],\n",
      "        [ 0.0470, -0.0108,  0.0182,  ...,  0.0556, -0.0558,  0.0345]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0107,  0.0438,  0.0219,  0.0109,  0.0222, -0.0563, -0.0551, -0.0219,\n",
      "        -0.0462, -0.0408, -0.0209, -0.0315,  0.0016,  0.0265, -0.0414, -0.0069,\n",
      "         0.0348,  0.0165,  0.0265, -0.0103,  0.0127,  0.0511,  0.0307,  0.0187,\n",
      "        -0.0165, -0.0468, -0.0002, -0.0522, -0.0140, -0.0413,  0.0131,  0.0507,\n",
      "        -0.0240, -0.0293,  0.0489,  0.0576, -0.0096, -0.0208, -0.0288, -0.0481,\n",
      "         0.0475, -0.0063,  0.0423,  0.0152,  0.0343, -0.0304, -0.0373, -0.0381,\n",
      "         0.0039,  0.0536,  0.0547,  0.0525, -0.0553, -0.0405,  0.0015,  0.0577,\n",
      "        -0.0467, -0.0536,  0.0206, -0.0478, -0.0315, -0.0287, -0.0212,  0.0469,\n",
      "         0.0440, -0.0477, -0.0448,  0.0215,  0.0010,  0.0139,  0.0251, -0.0076,\n",
      "        -0.0489,  0.0273, -0.0012,  0.0343, -0.0447, -0.0237,  0.0174,  0.0165,\n",
      "         0.0172, -0.0454,  0.0063,  0.0276,  0.0382,  0.0563, -0.0182,  0.0241,\n",
      "         0.0329, -0.0163, -0.0181, -0.0096,  0.0469, -0.0226, -0.0007,  0.0087,\n",
      "         0.0336,  0.0497, -0.0361,  0.0556,  0.0105,  0.0311,  0.0327,  0.0466,\n",
      "         0.0237,  0.0098,  0.0524,  0.0541,  0.0192,  0.0131, -0.0061, -0.0439,\n",
      "        -0.0247, -0.0570, -0.0410, -0.0424, -0.0022, -0.0152,  0.0111,  0.0103,\n",
      "        -0.0568, -0.0106, -0.0111,  0.0421, -0.0180,  0.0258, -0.0129, -0.0138,\n",
      "         0.0517,  0.0477,  0.0335,  0.0426,  0.0572,  0.0210,  0.0313, -0.0076,\n",
      "         0.0475, -0.0432,  0.0293,  0.0076, -0.0177, -0.0114, -0.0321,  0.0199,\n",
      "        -0.0147,  0.0089, -0.0367,  0.0054,  0.0087, -0.0344,  0.0379,  0.0384,\n",
      "        -0.0473, -0.0473, -0.0104,  0.0056,  0.0421,  0.0212,  0.0181,  0.0003,\n",
      "         0.0041,  0.0410, -0.0568,  0.0532,  0.0216,  0.0547, -0.0287,  0.0258,\n",
      "        -0.0037, -0.0433, -0.0164, -0.0261,  0.0273, -0.0415, -0.0156,  0.0368,\n",
      "         0.0167, -0.0102, -0.0464,  0.0124,  0.0006, -0.0147, -0.0095, -0.0082,\n",
      "         0.0411, -0.0321, -0.0080,  0.0105,  0.0172,  0.0460,  0.0312,  0.0088,\n",
      "        -0.0329,  0.0076, -0.0139, -0.0120,  0.0141, -0.0382, -0.0482,  0.0196,\n",
      "        -0.0486, -0.0291, -0.0357, -0.0219, -0.0450, -0.0394,  0.0541, -0.0526,\n",
      "        -0.0417, -0.0440, -0.0517,  0.0440, -0.0062,  0.0037,  0.0539,  0.0268,\n",
      "         0.0016, -0.0052,  0.0517, -0.0422, -0.0143,  0.0179,  0.0515,  0.0119,\n",
      "         0.0127,  0.0556,  0.0373, -0.0506, -0.0557,  0.0375,  0.0159, -0.0366,\n",
      "        -0.0319,  0.0513, -0.0211, -0.0057,  0.0172,  0.0152,  0.0535, -0.0337,\n",
      "         0.0128, -0.0378, -0.0532,  0.0144, -0.0528, -0.0179, -0.0389, -0.0276,\n",
      "         0.0016,  0.0420, -0.0534, -0.0527, -0.0393, -0.0352,  0.0276,  0.0184,\n",
      "        -0.0566, -0.0020,  0.0566,  0.0466, -0.0345, -0.0087, -0.0314,  0.0323,\n",
      "        -0.0014, -0.0205,  0.0533, -0.0365,  0.0168, -0.0481, -0.0260, -0.0010,\n",
      "        -0.0038, -0.0506, -0.0036, -0.0044, -0.0146, -0.0158,  0.0087, -0.0258,\n",
      "        -0.0381, -0.0139, -0.0389, -0.0348,  0.0288,  0.0259,  0.0304, -0.0389,\n",
      "        -0.0560, -0.0111, -0.0477, -0.0079, -0.0482,  0.0447,  0.0293, -0.0553,\n",
      "        -0.0109, -0.0120, -0.0168,  0.0560], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0373, -0.0087, -0.0237,  ..., -0.0396,  0.0438,  0.0071],\n",
      "        [-0.0072,  0.0239,  0.0220,  ..., -0.0199,  0.0114,  0.0215],\n",
      "        [-0.0100,  0.0103, -0.0419,  ..., -0.0187, -0.0460, -0.0111],\n",
      "        [-0.0340, -0.0254,  0.0136,  ..., -0.0260, -0.0055, -0.0516]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0284,  0.0031,  0.0414, -0.0208], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.9184e-02, -1.9191e-02, -4.3060e-02,  ..., -4.4212e-03,\n",
      "         -5.2578e-02,  2.6175e-02],\n",
      "        [-3.4583e-02, -3.2383e-02,  5.3333e-02,  ...,  9.1143e-04,\n",
      "         -4.9995e-02, -8.0570e-03],\n",
      "        [-5.0545e-02,  1.5887e-02,  4.8990e-02,  ..., -1.4254e-02,\n",
      "          5.5606e-02, -2.3320e-02],\n",
      "        [ 7.5865e-03, -1.5125e-02, -4.9732e-02,  ..., -4.0141e-02,\n",
      "         -8.2158e-05,  1.2758e-02]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0002, -0.0405, -0.0551,  0.0258], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for a in policy.parameters():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -4.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -4.37113883e-08,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.00000000e+01,  0.00000000e+00,\n",
       "        1.00000000e+00, -0.00000000e+00, -0.00000000e+00, -4.37113883e-08,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  8.36227417e-01, -1.00000000e+00,\n",
       "        7.95617676e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        7.76270628e-01])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(policy, torch.from_numpy(states[0]).to(device), 'rnn.onnx',opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute 'dot', make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, capture_output, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_lines\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[1;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mpopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    730\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1016\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Le fichier spécifié est introuvable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[1;34m(self, include, exclude, **_)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0minclude\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m                 if mimetype in include}\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\jupyter_integration.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     98\u001b[0m         return {mimetype: getattr(self, method_name)()\n\u001b[0;32m     99\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMIME_TYPES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                 if mimetype in include}\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_image_jpeg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\jupyter_integration.py\u001b[0m in \u001b[0;36m_repr_image_svg_xml\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_image_svg_xml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;34m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSVG_ENCODING\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36mpipe\u001b[1;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    102\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                                  encoding=encoding)\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_tools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecate_positional_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupported_number\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m                               category=category)\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[1;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    117\u001b[0m                                  \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                                  \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                                  encoding=encoding)\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     def _pipe_future(self, format: typing.Optional[str] = None, *,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[1;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[1;31m# common case: both stdin and stdout need the same encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\backend\\piping.py\u001b[0m in \u001b[0;36mpipe_lines_string\u001b[1;34m(engine, format, input_lines, encoding, renderer, formatter, quiet)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'input_lines'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m     \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Navigation2\\lib\\site-packages\\graphviz\\backend\\execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, capture_output, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute 'dot', make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x25f61164860>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(policy(states[0][0]), params=dict(policy.named_parameters()), show_attrs=True, show_saved=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6981, -0.6660, -0.9851, -0.5342], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### FAIRE REINFORCE EN ATTENDANT CAR C'EST PLUS SIMPLE ##############\n",
    "#probs = policy_network(state)\n",
    "# Note that this is equivalent to what used to be called multinomial\n",
    "#m = Categorical(probs)\n",
    "#action = m.sample()\n",
    "#next_state, reward = env.step(action)\n",
    "#loss = -m.log_prob(action) * reward\n",
    "#loss.backward()\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforce with twenty trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy_Reinforce(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size,nb_action):\n",
    "        super(Policy, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size,300)\n",
    "        self.fc2 = nn.Linear(300,300)\n",
    "        self.fc3 = nn.Linear(300,nb_action)\n",
    "        self.fc3bis = nn.Linear(300,nb_action)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mu = F.tanh(self.fc3(x))\n",
    "        #print(mu)\n",
    "        sigma = F.tanh(self.fc3bis(x)) # ¨b donne des sigma avec 0 veut que des sigma positif\n",
    "        sigma = torch.exp(sigma)\n",
    "        return sigma,mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #print(sigma)\n",
    "        m = torch.distributions.normal.Normal(mu,sigma,False)\n",
    "        #m = torch.distributions.multivariate_normal.MultivariateNormal(mu,sigma)\n",
    "        sample = m.sample()#.detach()\n",
    "        proba = m.log_prob(sample)\n",
    "        #print(\"Proba\")\n",
    "        #print(proba)\n",
    "        probab = torch.exp(proba)\n",
    "        #print(\"Probab\")\n",
    "        # action\n",
    "        action = torch.clip(sample.detach(), -1, 1)\n",
    "        # Genertes a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched.\n",
    "        \n",
    "        # Every entry in the action vector must be a number between -1 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################### MAIN_CODE #################################################\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]  \n",
    "states = env_info.vector_observations # get the current state (for each agent\n",
    "num_agents = len(states)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "nb_states = len(states[0])\n",
    "action_size = brain.vector_action_space_size\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy = Policy(nb_states,action_size).to(device)\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop max iterations\n",
    "episode = 500\n",
    "\n",
    "# widget bar to display progress\n",
    "#!pip install progressbar\n",
    "#import progressbar as pb\n",
    "#widget = ['training loop: ', pb.Percentage(), ' ', pb.Bar(), ' ', pb.ETA() ]\n",
    "#timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "\n",
    "discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta = .01\n",
    "tmax = 320\n",
    "SGD_epoch = 4\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    states, actions, rewards, prob = collect_trajectories(env,env_info, Policy_Reinforce,device)\n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "    print(total_rewards)\n",
    "\n",
    "    \n",
    "\n",
    "    # gradient ascent step\n",
    "    #for _ in range(SGD_epoch):\n",
    "        \n",
    "        # uncomment to utilize your own clipped function!\n",
    "        #L = -clipped_surrogate(policy,prob, states, rewards, epsilon=epsilon, beta=beta)\n",
    "    L = \n",
    "    optimizer.zero_grad()\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "        #del L\n",
    "    \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%20 ==0 :\n",
    "        print(\"################################\")\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = L\n",
    "A.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7209, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "R = torch.mean(L)\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAA -----> FOR PPO CONTINUOUS ACTION do Actor-Critic algo <-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-> On a en sortie [1001,20,4] <- Les valeurs des 4 actions. (Old_probs,New_probs) (pi(a,s),piprime(a,s))\n",
    "-> Fraction = Old_probs/New_probs (Attention les produits valeurs -1 et 1 problem potentiel) -> Rendre positif avant\n",
    "-> Clipping -> \n",
    "\n",
    "-> Reward * Fraction ([1001,20,4]*[1001,20,4])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Navigation2",
   "language": "python",
   "name": "navigation2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
